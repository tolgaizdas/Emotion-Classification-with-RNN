{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 11650,
     "sourceType": "datasetVersion",
     "datasetId": 8327
    },
    {
     "sourceId": 7563141,
     "sourceType": "datasetVersion",
     "datasetId": 4403839
    }
   ],
   "dockerImageVersionId": 30665,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from keras.layers import Embedding, Dense, Dropout, Flatten, GRU\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing import sequence\n",
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_bow_vectors(vectorizer, train_data, test_data, input_length):\n",
    "    # Create raw vectors\n",
    "    train_vectors, test_vectors = vectorizer.transform(train_data).toarray(), vectorizer.transform(test_data).toarray()\n",
    "\n",
    "    # Create bag-of-words vectors for each data\n",
    "    bow_train, bow_test = [], []\n",
    "    for vector in train_vectors:\n",
    "        bow_train.append(np.where(vector == 1)[0])\n",
    "    for vector in test_vectors:\n",
    "        bow_test.append(np.where(vector == 1)[0])\n",
    "\n",
    "    # Add padding to bow vectors\n",
    "    processed_train = sequence.pad_sequences(bow_train, input_length)\n",
    "    processed_test = sequence.pad_sequences(bow_test, input_length)\n",
    "\n",
    "    return processed_train, processed_test"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:34:48.532937Z",
     "iopub.execute_input": "2024-03-20T15:34:48.533173Z",
     "iopub.status.idle": "2024-03-20T15:34:48.544155Z",
     "shell.execute_reply.started": "2024-03-20T15:34:48.533152Z",
     "shell.execute_reply": "2024-03-20T15:34:48.543463Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_embedding_vectors(filename):\n",
    "    embedding_vectors = {}\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        for row in file:\n",
    "            values = row.split(' ')\n",
    "            word = values[0]\n",
    "            weights = np.asarray([float(val) for val in values[1:]])\n",
    "            embedding_vectors[word] = weights\n",
    "    print(f\"Size of vectorized vocabulary: {len(embedding_vectors)}\")\n",
    "    return embedding_vectors"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:34:48.546531Z",
     "iopub.execute_input": "2024-03-20T15:34:48.547136Z",
     "iopub.status.idle": "2024-03-20T15:34:48.555867Z",
     "shell.execute_reply.started": "2024-03-20T15:34:48.547102Z",
     "shell.execute_reply": "2024-03-20T15:34:48.555141Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def create_embedding_matrix(vocabulary, embedding_vectors, oov_words, emb_dim=300):\n",
    "    vocab_size = len(set(vocabulary))\n",
    "    embedding_matrix = np.zeros((vocab_size, emb_dim))\n",
    "\n",
    "    for word, idx in vocabulary.items():\n",
    "        if idx < vocab_size:\n",
    "            embedding_vector = embedding_vectors.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[idx] = embedding_vector\n",
    "            else:\n",
    "                oov_words.append(word)\n",
    "                # Random initialization for out of vocabulary words\n",
    "                embedding_matrix[idx] = np.random.uniform(low=-1.0, high=1.0, size=emb_dim)\n",
    "\n",
    "    return embedding_matrix"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:34:48.556903Z",
     "iopub.execute_input": "2024-03-20T15:34:48.557742Z",
     "iopub.status.idle": "2024-03-20T15:34:48.568474Z",
     "shell.execute_reply.started": "2024-03-20T15:34:48.557715Z",
     "shell.execute_reply": "2024-03-20T15:34:48.567574Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def get_prediction_results(model, test_data, labels_test):\n",
    "    predictions = model.predict(test_data)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    accuracy = accuracy_score(labels_test, predicted_labels)\n",
    "    report = classification_report(labels_test, predicted_labels, zero_division=1)\n",
    "    cm = confusion_matrix(labels_test, predicted_labels)\n",
    "\n",
    "    return accuracy, report, cm"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:49:03.373048Z",
     "iopub.execute_input": "2024-03-20T15:49:03.373433Z",
     "iopub.status.idle": "2024-03-20T15:49:03.379773Z",
     "shell.execute_reply.started": "2024-03-20T15:49:03.373404Z",
     "shell.execute_reply": "2024-03-20T15:49:03.378221Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load dataset\n",
    "dataset = pd.read_csv(\"/kaggle/input/emotions/text.csv\")\n",
    "\n",
    "# Extract data and labels from dataset\n",
    "data, labels = dataset['text'], dataset['label']\n",
    "\n",
    "# Split data into train and test data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.3, random_state=42)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:34:48.586224Z",
     "iopub.execute_input": "2024-03-20T15:34:48.586509Z",
     "iopub.status.idle": "2024-03-20T15:34:49.711108Z",
     "shell.execute_reply.started": "2024-03-20T15:34:48.586487Z",
     "shell.execute_reply": "2024-03-20T15:34:49.710300Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create count vectorizer\n",
    "n = 1\n",
    "vectorizer = CountVectorizer(analyzer='word', ngram_range=(n, n))\n",
    "vectorizer.fit(train_data)\n",
    "\n",
    "VOCABULARY_SIZE = len(set(vectorizer.vocabulary_))\n",
    "MAX_LENGTH = max(len(max(train_data, key=len)), len(max(test_data, key=len)))\n",
    "\n",
    "# Create bow vectors for each train and test data\n",
    "train_vectors, test_vectors = create_bow_vectors(vectorizer, train_data, test_data, input_length=MAX_LENGTH)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:34:49.712106Z",
     "iopub.execute_input": "2024-03-20T15:34:49.712396Z",
     "iopub.status.idle": "2024-03-20T15:36:38.918249Z",
     "shell.execute_reply.started": "2024-03-20T15:34:49.712373Z",
     "shell.execute_reply": "2024-03-20T15:36:38.917352Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Create embedding vectors\n",
    "embedding_vectors = create_embedding_vectors('/kaggle/input/glove840b300dtxt/glove.840B.300d.txt')\n",
    "\n",
    "# Create embedding matrix and out-of-vocabulary list\n",
    "oov_words = []\n",
    "embedding_matrix = create_embedding_matrix(vectorizer.vocabulary_, embedding_vectors, oov_words, emb_dim=300)\n",
    "\n",
    "# Print some of the out of vocabulary words\n",
    "print(f'Number of out of vocabulary words: {len(oov_words)}')\n",
    "print(f'Some out of vocabulary words: {oov_words[0:5]}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:36:38.919609Z",
     "iopub.execute_input": "2024-03-20T15:36:38.919895Z",
     "iopub.status.idle": "2024-03-20T15:40:25.755611Z",
     "shell.execute_reply.started": "2024-03-20T15:36:38.919871Z",
     "shell.execute_reply": "2024-03-20T15:40:25.754644Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "Size of vectorized vocabulary: 2196017\nNumber of out of vocabulary words: 9127\nSome out of vocabulary words: ['bodyjar', 'glimsp', 'immoduim', 'qasmaxs', 'wnfmcgill']\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Create the model\n",
    "model = keras.Sequential()\n",
    "embedding_layer = Embedding(VOCABULARY_SIZE, output_dim=embedding_matrix.shape[1], trainable=True)\n",
    "embedding_layer.build((None,))\n",
    "embedding_layer.set_weights([embedding_matrix])\n",
    "model.add(embedding_layer)\n",
    "model.add(GRU(128, return_sequences=True))\n",
    "model.add(GRU(64, return_sequences=True))\n",
    "model.add(GRU(32, return_sequences=False))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:40:25.758535Z",
     "iopub.execute_input": "2024-03-20T15:40:25.758871Z",
     "iopub.status.idle": "2024-03-20T15:40:26.844082Z",
     "shell.execute_reply.started": "2024-03-20T15:40:25.758845Z",
     "shell.execute_reply": "2024-03-20T15:40:26.843201Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the model\n",
    "model.fit(train_vectors, train_labels, epochs=10, batch_size=128, validation_split=0.3,\n",
    "          callbacks=[keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=1, restore_best_weights=True)])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:49:33.462027Z",
     "iopub.execute_input": "2024-03-20T15:49:33.462915Z",
     "iopub.status.idle": "2024-03-20T15:57:06.171777Z",
     "shell.execute_reply.started": "2024-03-20T15:49:33.462882Z",
     "shell.execute_reply": "2024-03-20T15:57:06.170715Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/10\n\u001B[1m1596/1596\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m226s\u001B[0m 142ms/step - accuracy: 0.9059 - loss: 0.2195 - val_accuracy: 0.8991 - val_loss: 0.2111\nEpoch 2/10\n\u001B[1m1596/1596\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m225s\u001B[0m 141ms/step - accuracy: 0.9161 - loss: 0.1881 - val_accuracy: 0.8947 - val_loss: 0.2184\n",
     "output_type": "stream"
    },
    {
     "execution_count": 13,
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.src.callbacks.history.History at 0x7e8934159480>"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Print results\n",
    "accuracy, report, cm = get_prediction_results(model, test_vectors, test_labels)\n",
    "\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-20T15:57:17.462572Z",
     "iopub.execute_input": "2024-03-20T15:57:17.462969Z",
     "iopub.status.idle": "2024-03-20T15:59:02.715589Z",
     "shell.execute_reply.started": "2024-03-20T15:57:17.462935Z",
     "shell.execute_reply": "2024-03-20T15:59:02.714585Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[1m3908/3908\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m102s\u001B[0m 26ms/step\n\nConfusion Matrix:\n [[33996   572   176   521   928    68]\n [  576 37150  3277   352   429   471]\n [  106   303  9685    83    34    30]\n [ 1173   252    56 15621   173    20]\n [  323   116    49   879 12654   373]\n [   92    86    16    38   922  3443]]\n\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.94      0.94      0.94     36261\n           1       0.97      0.88      0.92     42255\n           2       0.73      0.95      0.82     10241\n           3       0.89      0.90      0.90     17295\n           4       0.84      0.88      0.86     14394\n           5       0.78      0.75      0.76      4597\n\n    accuracy                           0.90    125043\n   macro avg       0.86      0.88      0.87    125043\nweighted avg       0.91      0.90      0.90    125043\n\nAccuracy: 0.90\n",
     "output_type": "stream"
    }
   ]
  }
 ]
}
